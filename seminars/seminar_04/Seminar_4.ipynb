{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bcWIvZ3z2lzW"
   },
   "source": [
    "# Семинар 4 - Интерполяция изображений, геометрия формирования изображения и калибровка камеры\n",
    "\n",
    "***\n",
    "\n",
    "**Данный семинар содержит домашнее задание - оцениваемые упражнения и вопросы.**\n",
    "\n",
    "Система оценивания: доля правильно решенных упражений. Максимальный балл, соответственно, 1.\n",
    "\n",
    "В упражнениях оценивается два аспекта:\n",
    "1. Код проходит assert'ы (если они есть)\n",
    "2. Код корректен с точки зрения логики\n",
    "\n",
    "Вопросы также оцениваются. Ответ на них нужно записывать в соответствующие markdown-ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjieVH2p5eBj"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные материалы по теме семинара\n",
    "\n",
    "- [YouTube: Resizing Images - Computerphile](https://youtu.be/AqscP7rc8_M?si=2l8fH_P_ghtzuFb7)\n",
    "- [YouTube: Bicubic Interpolation - Computerphile](https://youtu.be/poY_nGzEEWM?si=G9W6mRjlsYPyyspN)\n",
    "- [YouTube: Lanczos interpolation and resampling | Image processing](https://youtu.be/ijmd6XyG2HA?si=rIFwZSTUVVgrqo4I)\n",
    "- [Interpolation Algorithms in PixInsight](https://pixinsight.com/doc/docs/InterpolationAlgorithms/InterpolationAlgorithms.html)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZTkutUy4f-Y"
   },
   "source": [
    "## Интерполяция изображений\n",
    "\n",
    "![](data/interpolation.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм пересчёта координат для масштабирования изображения\n",
    "\n",
    "Данный алгоритм позволяет определить соответствие между пикселями нового и исходного изображений при масштабировании. Сначала вычисляются масштабные коэффициенты, затем для каждого пикселя нового изображения определяется соответствующая точка в исходном изображении. Это обеспечивает базу для применения методов интерполяции (nearest neighbor, bilinear, bicubic) с целью восстановления значений пикселей.\n",
    "\n",
    "1. **Исходные данные:**\n",
    "\n",
    "   - Исходное изображение: $W_{\\text{orig}} \\times H_{\\text{orig}}$\n",
    "   - Новое изображение: $W_{\\text{new}} \\times H_{\\text{new}}$\n",
    "\n",
    "2. **Вычисление масштабных коэффициентов:**\n",
    "\n",
    "   $$k_x = \\frac{W_{\\text{orig}} - 1}{W_{\\text{new}} - 1}, \\quad k_y = \\frac{H_{\\text{orig}} - 1}{H_{\\text{new}} - 1}$$\n",
    "\n",
    "3. **Пересчёт координат:**\n",
    "\n",
    "   - Для каждого пикселя нового изображения с координатами \\((i, j)\\) вычисляем координаты в исходном изображении:\n",
    "\n",
    "     $$x = i \\times k_x, \\quad y = j \\times k_y$$\n",
    "\n",
    "4. **Применение интерполяции:**\n",
    "\n",
    "   - **Nearest Neighbor:** округление до ближайшего целого значения.\n",
    "   - **Bilinear:** использование четырёх ближайших пикселей с линейными весами.\n",
    "   - **Bicubic:** использование 16 ближайших пикселей с кубическими весовыми функциями.\n",
    "\n",
    "Такой алгоритм пересчета гарантирует, что угловые пиксели нового изображения будут соответствовать угловым пикселям исходного изображения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерполяция по ближайшему соседу (Nearest Neighbor)\n",
    "\n",
    "**Формула:**\n",
    "\n",
    "Для получения координат пикселя, ближайшего к вычисленным $(x, y)$, применяется функция округления:\n",
    "\n",
    "$$x' = f_{\\text{round}}(x), \\quad y' = f_{\\text{round}}(y)$$\n",
    "\n",
    "Здесь:\n",
    "- $(x, y)$ – координаты нового пикселя в исходном масштабе (как вычислено выше),\n",
    "- $f_{\\text{round}}()$ – функция округления, которая выбирает ближайший пиксель. В OpenCV для положительных значений применяется округление «в сторону ближе к 0» (то есть, функция $\\text{floor}()$). Подробное рассмотрение влияния различных функций округления на интерполяцию по ближайшему соседу можно найти в статье: https://arxiv.org/abs/2003.06885.\n",
    "\n",
    "**Принцип работы:**\n",
    "\n",
    "Метод ближайшего соседа просто копирует значение ближайшего исходного пикселя. Это делает его быстрым, но приводит к характерным ступенчатым артефактам.\n",
    "\n",
    "**Плюсы:**\n",
    "\n",
    "- Высокая скорость выполнения.\n",
    "- Полное сохранение резких границ в масках и бинарных изображениях.\n",
    "\n",
    "**Минусы:**\n",
    "\n",
    "- Грубые визуальные артефакты, особенно при увеличении.\n",
    "- Потеря гладкости и непрерывности.\n",
    "\n",
    "**Пример: Увеличение 3×3 → 6×6**\n",
    "\n",
    "Исходное 3×3:\n",
    "\n",
    "```\n",
    "A B C\n",
    "D E F\n",
    "G H I\n",
    "```\n",
    "\n",
    "После увеличения (6×6):\n",
    "\n",
    "```\n",
    "A A B B C C\n",
    "A A B B C C\n",
    "D D E E F F\n",
    "D D E E F F\n",
    "G G H H I I\n",
    "G G H H I I\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример кода\n",
    "\n",
    "В OpenCV интерполяция по ближайшему соседу реализуется функцией `cv2.resize()` с параметром интерполяции `cv2.INTER_NEAREST`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_letter = cv2.imread('data/a_letter.png', cv2.IMREAD_GRAYSCALE)\n",
    "print(f\"a_letter.shape: {a_letter.shape}\")\n",
    "\n",
    "a_letter_resized_nn_opencv = cv2.resize(a_letter, (200, 200), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(a_letter, cmap='gray')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(a_letter_resized_nn_opencv, cmap='gray')\n",
    "plt.title('Resized with NN')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 1\n",
    "\n",
    "_Этот и дальнейшие вопросы и упражнения будут оцениваться_\n",
    "\n",
    "Что происходит при изменении размера в нецелое число раз? Дополните пример - как будет выглядеть \"изображение\" после увеличения до (5×5), если мы интерполируем его с помощью OpenCV?\n",
    "\n",
    "**Ответ:**\n",
    "\n",
    "???\n",
    "\n",
    "**Пример:**\n",
    "\n",
    "Исходное 3×3:\n",
    "\n",
    "```\n",
    "A B C\n",
    "D E F\n",
    "G H I\n",
    "```\n",
    "\n",
    "После увеличения (5×5) с `cv2.INTER_NEAREST`:\n",
    "\n",
    "```\n",
    "? ? ? ? ?\n",
    "? ? ? ? ?\n",
    "? ? ? ? ?\n",
    "? ? ? ? ?\n",
    "? ? ? ? ?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 1\n",
    "\n",
    "Реализуйте функцию `resize_nearest_neighbor`, которая выполняет интерполяцию по ближайшему соседу. Функция принимает на вход исходное изображение и новый размер, а возвращает новое изображение. Сравнивайте результаты с функцией `cv2.resize` с параметром интерполяции `cv2.INTER_NEAREST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_nearest_neighbor(img: np.ndarray, new_size: tuple[int]) -> np.ndarray:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.zeros((3, 3), dtype=np.uint8)\n",
    "for x in range(3):\n",
    "    for y in range(3):\n",
    "        sample[x, y] = x * 10 + y\n",
    "print(\"Исходное 3×3:\")\n",
    "print('\\n'.join([' '.join([f'{item:02}' for item in row]) for row in sample]))\n",
    "\n",
    "sample_resized_nn_opencv = cv2.resize(\n",
    "    src=sample,\n",
    "    dsize=(5, 5),\n",
    "    interpolation=cv2.INTER_NEAREST,\n",
    ")\n",
    "print(\"\\nПосле увеличения до 5×5 с помощью OpenCV:\")\n",
    "print('\\n'.join([' '.join([f'{item:02}' for item in row]) for row in sample_resized_nn_opencv]))\n",
    "\n",
    "sample_resized_nn_custom = resize_nearest_neighbor(sample, (5, 5))\n",
    "print(\"\\nПосле увеличения до 5×5 своей функцией:\")\n",
    "print('\\n'.join([' '.join([f'{item:02}' for item in row]) for row in sample_resized_nn_custom]))\n",
    "\n",
    "assert np.all(sample_resized_nn_opencv == sample_resized_nn_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Билинейная интерполяция (Bilinear Interpolation)\n",
    "\n",
    "Билинейная интерполяция использует линейное взвешенное усреднение четырех ближайших пикселей, вычисляя значение нового пикселя как функцию их значений и расстояния до них. Это дает более плавные переходы по сравнению с методом ближайшего соседа.\n",
    "\n",
    "**Пошаговый алгоритм:**\n",
    "\n",
    "1. **Определение координат:**  \n",
    "\n",
    "   Пусть необходимо вычислить значение пикселя в точке с координатами $(x, y)$, где $x$ и $y$ могут быть дробными. Определите ближайшие целочисленные координаты, ограничивающие эту точку:\n",
    "\n",
    "   - $x_1 = \\lfloor x \\rfloor$ — наибольшее целое число, не превышающее $x$\n",
    "   - $x_2 = x_1 + 1$\n",
    "   - $y_1 = \\lfloor y \\rfloor$\n",
    "   - $y_2 = y_1 + 1$\n",
    "\n",
    "2. **Получение значений четырёх соседних пикселей:**\n",
    "\n",
    "   Обозначим значение пикселя в точке $(i, j)$ как $f(i, j)$. Тогда:\n",
    "\n",
    "   - $f(x_1, y_1)$ — верхний левый пиксель\n",
    "   - $f(x_2, y_1)$ — верхний правый пиксель\n",
    "   - $f(x_1, y_2)$ — нижний левый пиксель\n",
    "   - $f(x_2, y_2)$ — нижний правый пиксель\n",
    "\n",
    "3. **Линейная интерполяция по оси $x$:**\n",
    "\n",
    "   Вычисляем промежуточные значения для двух строк:\n",
    "\n",
    "   - Для $y = y_1$:\n",
    "\n",
    "     $$f_{y1}(x) = f(x_1, y_1) \\cdot (x_2 - x) + f(x_2, y_1) \\cdot (x - x_1)$$\n",
    "\n",
    "   - Для $y = y_2$:\n",
    "\n",
    "     $$f_{y2}(x) = f(x_1, y_2) \\cdot (x_2 - x) + f(x_2, y_2) \\cdot (x - x_1)$$\n",
    "\n",
    "\n",
    "4. **Линейная интерполяция по оси $y$:**  \n",
    "\n",
    "   Интерполируем между $f_{y1}(x)$ и $f_{y2}(x)$ по оси $y$:\n",
    "\n",
    "   $$f(x, y) = f_{y1}(x) \\cdot (y_2 - y) + f_{y2}(x) \\cdot (y - y_1)$$\n",
    "\n",
    "5. **Нормировка (при необходимости):**  \n",
    "\n",
    "   Если разницы $x_2 - x_1$ и $y_2 - y_1$ не равны 1, итоговая формула может включать деление на $(x_2 - x_1)(y_2 - y_1)$.\n",
    "\n",
    "   В стандартной ситуации для изображений, где пиксели располагаются через один и тот же интервал (то есть $x_2 - x_1 = 1$ и $y_2 - y_1 = 1$), нормировка не требуется, так как знаменатель равен 1.\n",
    "\n",
    "**Итоговая формула:**\n",
    "\n",
    "Объединяя шаги, получаем:\n",
    "\n",
    "$$f(x, y) = f(x_1, y_1)(x_2 - x)(y_2 - y) + f(x_2, y_1)(x - x_1)(y_2 - y) + f(x_1, y_2)(x_2 - x)(y - y_1) + f(x_2, y_2)(x - x_1)(y - y_1)$$\n",
    "\n",
    "> **Примечание:** знаменатель $(x_2 - x_1)(y_2 - y_1)$ здесь опущен, так как в случае изображений он равен 1.\n",
    "\n",
    "**Плюсы:**\n",
    "\n",
    "- Более гладкие градиенты и отсутствие резких артефактов.\n",
    "- Умеренная вычислительная сложность.\n",
    "\n",
    "**Минусы:**\n",
    "\n",
    "- Размытость границ, особенно в высококонтрастных участках.\n",
    "- Не учитывает сложные изменения в структуре изображения.\n",
    "\n",
    "**Пример: Увеличение 3×3 → 6×6**\n",
    "\n",
    "Исходное 3×3:\n",
    "\n",
    "```\n",
    "10 20 30\n",
    "40 50 60\n",
    "70 80 90\n",
    "```\n",
    "\n",
    "После увеличения (6×6) с билинейной интерполяцией:\n",
    "\n",
    "```\n",
    "10 14 18 22 26 30\n",
    "22 26 30 34 38 42\n",
    "34 38 42 46 50 54\n",
    "46 50 54 58 62 66\n",
    "58 62 66 70 74 78\n",
    "70 74 78 82 86 90\n",
    "```\n",
    "\n",
    "Каждый новый пиксель получает значение, рассчитанное на основе билинейного взвешенного усреднения четырех ближайших соседних значений, что приводит к более плавным переходам между исходными значениями.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример кода\n",
    "\n",
    "В OpenCV билинейная интерполяция соответствует методу `cv2.INTER_LINEAR`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_letter_resized_bilinear_opencv = cv2.resize(\n",
    "    a_letter,\n",
    "    (200, 200),\n",
    "    interpolation=cv2.INTER_LINEAR,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(a_letter, cmap='gray')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(a_letter_resized_bilinear_opencv, cmap='gray')\n",
    "plt.title('Resized with Bilinear interpolation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 2\n",
    "\n",
    "Реализуйте функцию `resize_bilinear_interpolation` для билинейной интерполяции изображения. Функция должна принимать на вход исходное изображение и размер нового изображения, а возвращать новое изображение, интерполированное методом билинейной интерполяции.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_bilinear_interpolation(img: np.ndarray, new_size: tuple[int]) -> np.ndarray:\n",
    "    \"\"\"Performs bilinear interpolation on the input image to resize it to the new dimensions.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image as a 2D numpy array.\n",
    "        new_size (tuple[int]): Desired size for the output image as (new_height, new_width).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Resized image as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.arange(1, 10, dtype=np.uint8).reshape(3, 3) * 10\n",
    "print(\"\\nИсходное 3×3:\")\n",
    "print(sample)\n",
    "\n",
    "sample_resized_1 = resize_bilinear_interpolation(sample, (6, 6))\n",
    "print(\"\\nПосле увеличения до 6×6 c помощью своей функции:\")\n",
    "print(sample_resized_1)\n",
    "\n",
    "sample_resized_2 = cv2.resize(\n",
    "    src=sample,\n",
    "    dsize=(6, 6),\n",
    "    interpolation=cv2.INTER_LINEAR,\n",
    ")\n",
    "print(\"\\nПосле увеличения до 6×6 c помощью OpenCV:\")\n",
    "print(sample_resized_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бикубическая интерполяция (Bicubic Interpolation)\n",
    "\n",
    "Бикубическая интерполяция идёт дальше билинейной, используя **16 ближайших пикселей** (по 4 вдоль каждой оси). Вместо простой линейной аппроксимации здесь используется **кубическая** функция, что даёт более плавные переходы и, зачастую, лучшее качество в плавных градиентах. Однако метод сложнее в вычислительном плане и может создавать артефакты (гало-эффекты) вокруг резких границ.\n",
    "\n",
    "1. **Определение координат**  \n",
    "\n",
    "   Как и в билинейной интерполяции, сначала нужно вычислить, какие координаты в исходном изображении соответствуют точке $(x, y)$ в новом изображении (с учётом масштабных коэффициентов). Пусть\n",
    "   $$\n",
    "   x = i \\cdot k_x, \\quad y = j \\cdot k_y,\n",
    "   $$\n",
    "\n",
    "   где $k_x$ и $k_y$ — масштабные коэффициенты, а $(i, j)$ — координаты пикселя в результирующем изображении.\n",
    "\n",
    "2. **Выбор 16 соседних пикселей**  \n",
    "   \n",
    "   Пусть $\\lfloor x \\rfloor = x_1$ и $\\lfloor y \\rfloor = y_1$. Тогда набор координат выглядит так:\n",
    "\n",
    "   - $(x_1 - 1,\\; y_1 - 1)$, $(x_1,\\; y_1 - 1)$, $(x_1 + 1,\\; y_1 - 1)$, $(x_1 + 2,\\; y_1 - 1)$\n",
    "   - $(x_1 - 1,\\; y_1)$,   $(x_1,\\; y_1)$,   $(x_1 + 1,\\; y_1)$,   $(x_1 + 2,\\; y_1)$\n",
    "   - $(x_1 - 1,\\; y_1 + 1)$, $(x_1,\\; y_1 + 1)$, $(x_1 + 1,\\; y_1 + 1)$, $(x_1 + 2,\\; y_1 + 1)$\n",
    "   - $(x_1 - 1,\\; y_1 + 2)$, $(x_1,\\; y_1 + 2)$, $(x_1 + 1,\\; y_1 + 2)$, $(x_1 + 2,\\; y_1 + 2)$\n",
    "\n",
    "   Всего получается 16 значений пикселей исходного изображения, влияющих на значение точки $(x, y)$.\n",
    "\n",
    "3. **Кубическая интерполяция по одной из осей (например, по $x$)**  \n",
    "   \n",
    "   Для каждой из четырёх строк (фиксированного $y_n$) выполняют **одномерную кубическую интерполяцию** по оси $x$. Результатом становятся 4 промежуточных значения — по одному для каждой строки.\n",
    "\n",
    "4. **Кубическая интерполяция по другой оси (по $y$)**  \n",
    "   \n",
    "   Полученные 4 промежуточных значения снова интерполируются между собой **кубической функцией**, но уже по оси $y$. Итог — одно число: интенсивность (или цвет) нового пикселя $(x, y)$.\n",
    "\n",
    "5. **Использование кубического ядра**  \n",
    "   \n",
    "   На практике часто применяют **форму кубического сплайн-ядра** вида:\n",
    "   \n",
    "   $$\n",
    "   w(t) = \n",
    "   \\begin{cases}\n",
    "     (a+2)|t|^3 - (a+3)|t|^2 + 1, & |t| \\le 1 \\\\\n",
    "     a|t|^3 - 5a|t|^2 + 8a|t| - 4a, & 1 < |t| \\le 2 \\\\\n",
    "     0, & |t| > 2\n",
    "   \\end{cases}\n",
    "   $$\n",
    "   \n",
    "   где $a$ (обычно $-0.5$) задаёт форму кривой. Такое ядро применяют отдельно по осям $x$ и $y$, сворачивая значения 16 пикселей с соответствующими весовыми коэффициентами.\n",
    "\n",
    "**Итоговая формула:**\n",
    "\n",
    "В свёрточном виде бикубическая интерполяция может быть записана так:\n",
    "\n",
    "$$\n",
    "f(x, y) = \\sum_{m=-1}^{2} \\sum_{n=-1}^{2} f(x_1 + m,\\; y_1 + n)\\; w(m - dx)\\; w(n - dy),\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "- $x_1 = \\lfloor x \\rfloor$, $\\; y_1 = \\lfloor y \\rfloor$,\n",
    "- $dx = x - x_1$, $\\; dy = y - y_1$,\n",
    "- $w(\\cdot)$ — указанное выше **кубическое сплайн-ядро**,\n",
    "- $f(i, j)$ — значение пикселя в точке $(i, j)$ исходного изображения.\n",
    "\n",
    "**Плюсы:**\n",
    "\n",
    "- Даёт превосходные результаты для плавных градиентов и текстур.\n",
    "- Часто выглядит “профессиональнее” при увеличении.\n",
    "\n",
    "**Минусы:**\n",
    "\n",
    "- Вычислительно дороже, чем билинейная и ближайший сосед.\n",
    "- Может вызывать [эффект гало](https://ru.wikipedia.org/wiki/Гало) и “звон” на резких границах.\n",
    "\n",
    "\n",
    "**Пример: Увеличение 4×4 → 8×8**\n",
    "\n",
    "Исходное 4×4:\n",
    "\n",
    "```\n",
    " 10  20  30  40\n",
    " 50  60  70  80\n",
    " 90 100 110 120\n",
    "130 140 150 160\n",
    "```\n",
    "\n",
    "После увеличения (8×8) с бикубической интерполяцией (ядро $a = -0.5$):\n",
    "\n",
    "```\n",
    " 10  14  18  23  28  33  38  40\n",
    " 30  36  42  48  55  61  66  68\n",
    " 50  56  63  70  78  85  90  92\n",
    " 71  77  84  91  99 106 111 113\n",
    " 91  98 105 112 120 127 133 136\n",
    "111 119 126 134 142 149 155 158\n",
    "131 139 147 155 163 170 176 179\n",
    "130 137 144 152 159 166 172 160\n",
    "```\n",
    "\n",
    "(Значения приблизительны и приведены для иллюстрации. Реальные числа зависят от точного ядра и точности вычислений.)\n",
    "\n",
    "Таким образом, бикубическая интерполяция даёт **более плавные** переходы среди классических методов, но требует больших вычислительных затрат и может вносить нежелательные артефакты на резких границах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример кода\n",
    "\n",
    "В OpenCV бикубическая интерполяция соответствует методу `cv2.INTER_CUBIC`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_letter_resized_bicubic_opencv = cv2.resize(\n",
    "    a_letter,\n",
    "    (200, 200),\n",
    "    interpolation=cv2.INTER_CUBIC,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(a_letter, cmap='gray')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(a_letter_resized_bicubic_opencv, cmap='gray')\n",
    "plt.title('Resized with Bicubic interpolation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эффект гало"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50\n",
    "background_color = 128  # светло-серый фон\n",
    "border_color = 32       # более тёмный оттенок\n",
    "radius_1 = 15\n",
    "radius_2 = 11\n",
    "center = (size // 2, size // 2)  # Координаты центра\n",
    "\n",
    "# Создаем 50x50 изображение, заполненное фоновым цветом\n",
    "ring_img = np.full((size, size), background_color, dtype=np.uint8)\n",
    "\n",
    "# Рисуем кольцо\n",
    "for y in range(size):\n",
    "    for x in range(size):\n",
    "        dist = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "        if dist < radius_1 and dist >= radius_2:\n",
    "            ring_img[y, x] = border_color\n",
    "\n",
    "ring_img_resized_bicubic_opencv = cv2.resize(\n",
    "    ring_img,\n",
    "    (500, 500),\n",
    "    interpolation=cv2.INTER_CUBIC,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(ring_img, cmap='gray',vmin=0, vmax=255)\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(ring_img[20:30, 8:18], cmap='gray',vmin=0, vmax=255)\n",
    "plt.title('Zoom-in original')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(ring_img_resized_bicubic_opencv, cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('Resized with Bicubic interpolation')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(ring_img_resized_bicubic_opencv[200:300, 80:180], cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('Zoom-in resized')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 2\n",
    "\n",
    "Как влияет выбор параметра $a$ в формуле кубического сплайн-ядра (например, $a=−0.5,−0.75,−1.0$) на итоговое качество бикубической интерполяции (эффект гало, степень размытия, резкость границ)? Существует ли оптимальный выбор $a$, уравновешивающий гало-артефакты и степень сглаживания?\n",
    "\n",
    "**Ответ:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие методы интерполяции\n",
    "\n",
    "### **Area (Интерполяция по площади)**\n",
    "\n",
    "**Идея**\n",
    "\n",
    "Для каждого нового пикселя определяется та часть (проекция) в исходном изображении, которая ему соответствует. Далее берется **среднее значение** (либо взвешенное, если проекция пересекает несколько пикселей частично) всей этой области.\n",
    "\n",
    "**Как определяется “проекция”?**\n",
    "\n",
    "1. Допустим, мы знаем масштабный коэффициент (по $x$ и $y$).  \n",
    "2. Для пикселя $(i, j)$ в новом изображении вычисляется соответствующая область $[x_{\\text{min}},\\, x_{\\text{max}}) \\times [y_{\\text{min}},\\, y_{\\text{max}})$ в старом изображении.  \n",
    "3. Все пиксели старого изображения, которые частично или полностью лежат в этой области, учитываются при усреднении. Если пиксель пересекается не полностью, учитывается только доля площади пересечения.\n",
    "\n",
    "**Применение**  \n",
    "\n",
    "- **Наиболее эффективно** при **уменьшении** (downsampling), так как такое “интегрирование” позволяет избежать артефактов передискретизации (aliasing).  \n",
    "- При увеличении (upsampling) визуальный результат обычно хуже, чем у билинейной, бикубической или Lanczos.  \n",
    "- В OpenCV вызывается методом `cv2.INTER_AREA`.\n",
    "\n",
    "### **Lanczos (Ланцош-фильтр)**\n",
    "\n",
    "**Идея**  \n",
    "\n",
    "Lanczos — это **свёртка** с окном (windowed) **sinc-функции**. Функция $\\text{sinc}(x)$ обычно определяется как:\n",
    "\n",
    "$$\n",
    "\\text{sinc}(x) = \n",
    "\\begin{cases}\n",
    "\\frac{\\sin(\\pi x)}{\\pi x}, & x \\ne 0,\\\\\n",
    "1, & x=0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Вместо бесконечного sinc используют окно (то есть “обрезают” её), чтобы фильтр был конечной длины. Количество “лепестков” (lobes) за пределами центрального пика определяет порядок Lanczos:  \n",
    "\n",
    "- Lanczos2 — два “лепестка” в каждую сторону,  \n",
    "- Lanczos3 — три и т. д.\n",
    "\n",
    "Тогда функция **Lanczos** определяется следующим образом:\n",
    "\n",
    "$$\n",
    "L(x; n > 0) =\n",
    "\\begin{cases}\n",
    "\\text{sinc}(x) \\cdot \\text{sinc}(x/n), & |x| \\le n, \\\\\n",
    "0, & |x| > n.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Что такое “лепестки” (lobes)?**  \n",
    "\n",
    "На графике $\\sin(\\pi x)/(\\pi x)$ после центрального пика видны волнообразные “отрицательные” и “положительные” колебания (их называют лепестками, или lobes). Чем дальше мы отходим от нуля, тем меньше “вес” пикселя, но тем более “расширенной” становится поддержка фильтра.\n",
    "\n",
    "**Применение**  \n",
    "\n",
    "- Lanczos даёт **высокое качество** при увеличении и уменьшении, часто превосходя бикубический метод для плавных градиентов и детальных текстур.  \n",
    "- Может создавать **“звон” (ringing artifacts)** вокруг резких переходов, так как sinc-функция имеет волновую природу и не “загрублена” вблизи обрывов.  \n",
    "- В OpenCV реализован как `cv2.INTER_LANCZOS4` (четыре лепестка).\n",
    "\n",
    "**График функции Lanczos4**\n",
    "\n",
    "![lanczos4_func](./data/Lanczos4FunctionGraph.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 3\n",
    "\n",
    "Реализуйте функцию `resize_lanczos` для интерполяции методом Ланцоша. Функция должна принимать на вход исходное изображение и размер нового изображения, а возвращать новое изображение, интерполированное методом Ланцоша.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lanczos_kernel(x: np.ndarray, a: int = 4) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the Lanczos kernel for a given x and parameter a (sinc window).\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Coordinate (difference between filter index and target point).\n",
    "        a (int): Kernel radius (usually 2, 3, or 4).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Weight coefficient.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def resize_lanczos(img: np.ndarray, new_size: tuple[int, int], a: int = 4) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs image interpolation using the Lanczos method.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        new_size (tuple[int, int]): New size as (new_width, new_height).\n",
    "        a (int): Lanczos window radius (default is 4).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Interpolated image.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# Применяем интерполяцию Lanczos\n",
    "a_letter_resized_lanczos_custom = resize_lanczos(a_letter, (200, 200), a=4)\n",
    "\n",
    "# Визуализация результата\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(a_letter, cmap='gray')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(a_letter_resized_lanczos_custom, cmap='gray')\n",
    "plt.title('Resized with Lanczos interpolation')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение методов в OpenCV\n",
    "\n",
    "Согласно [документации OpenCV](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html) для **сжатия изображения** — наиболее предпочтительным методом интерполяции является `cv.INTER_AREA`,\n",
    "**для увеличения изображения** — наиболее предпочтительны методы интерполяции: `cv.INTER_CUBIC` (медленный) и `cv.INTER_LINEAR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "executionInfo": {
     "elapsed": 3141,
     "status": "ok",
     "timestamp": 1644862858479,
     "user": {
      "displayName": "Дмитрий Александрович Юдин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09652559510612614952"
     },
     "user_tz": -180
    },
    "id": "vrrzFGn82nFN",
    "outputId": "ad9c6a19-f3e9-4d15-9d37-c21e6d05b3c4"
   },
   "outputs": [],
   "source": [
    "interpolation_algorithm = [\n",
    "    (\"nearest\", cv2.INTER_NEAREST),\n",
    "    (\"bilinear\", cv2.INTER_LINEAR),\n",
    "    (\"bicubic\", cv2.INTER_CUBIC),\n",
    "    (\"area\", cv2.INTER_AREA),\n",
    "    (\"lanczos4\", cv2.INTER_LANCZOS4)\n",
    "]\n",
    "\n",
    "def resize_by_factor(\n",
    "    img: np.array,\n",
    "    factor: float,\n",
    ") -> None:\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "    height2, width2 = int(height*factor), int(width*factor)\n",
    "\n",
    "    print(f'orig size: h={height}, w={width}, resised size: h={height2}, w={width2}')\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(interpolation_algorithm),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        figsize=(3, 20)\n",
    "    )\n",
    "\n",
    "    imgs = []\n",
    "    for i in range(len(interpolation_algorithm)):\n",
    "\n",
    "        img_resized = cv2.resize(\n",
    "            src=img,\n",
    "            dsize=(width2, height2),\n",
    "            interpolation=interpolation_algorithm[i][1],\n",
    "        )\n",
    "\n",
    "        axes[i].imshow(img_resized, cmap='Greys_r')\n",
    "        axes[i].set_title(\n",
    "            f\"{interpolation_algorithm[i][0]}, shape = {img_resized.shape}\",\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оригинальное изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"data/a_letter.png\"\n",
    "\n",
    "if not Path(IMG_PATH).exists():\n",
    "    !git clone https://github.com/alexmelekhin/cv_course_2023.git\n",
    "    !mv cv_course_2023/seminars/seminar_04/data .\n",
    "\n",
    "a_letter_img = cv2.imread(IMG_PATH, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(a_letter_img, cmap=\"Greys_r\")\n",
    "plt.title(f\"Original image, shape = {a_letter_img.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_by_factor(\n",
    "    img=a_letter_img,\n",
    "    factor=5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "N58DtnpHA8qI",
    "outputId": "73fc8e11-b414-49ab-f206-7c21f4fb203a"
   },
   "outputs": [],
   "source": [
    "resize_by_factor(\n",
    "    img=a_letter_img,\n",
    "    factor=0.5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3-4vDr17KHts"
   },
   "source": [
    "## Упражение 3\n",
    "\n",
    "Можно ли реализовать функцию уменьшения изображения, используя свёртки?\n",
    "Напишите такую функцию, которая уменьшает изображение в N раз, применяя свёрточный фильтр усреднения перед выборкой.\n",
    "\n",
    "**Подсказка:**\n",
    "\n",
    "- Используйте размывающий фильтр (например, ядро усреднения)\n",
    "- Используйте стандартный оператор свёртки (`cv2.filter2D`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmTTEQCNAm_i"
   },
   "outputs": [],
   "source": [
    "def downsample_with_convolution(img: np.ndarray, scale_factor: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downsamples an image using convolution before subsampling.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        scale_factor (int): Factor by which to downsample the image (must be >= 2).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Downsampled image.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If scale_factor is less than 2.\n",
    "    \"\"\"\n",
    "    if scale_factor < 2:\n",
    "        raise ValueError(\"Scale factor must be >= 2\")\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "a_letter_downsampled_convolution = downsample_with_convolution(a_letter, 2)\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(a_letter, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(a_letter_downsampled_convolution, cmap='gray')\n",
    "plt.title(\"Downsampled Image (x2)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yaJIxPgXKabS"
   },
   "source": [
    "## Трансформация изображений\n",
    "\n",
    "[Туториал OpenCV \"Geometric Transformations of Images\"](https://docs.opencv.org/3.4/da/d6e/tutorial_py_geometric_transformations.html)\n",
    "\n",
    "### Поворот (Rotation)\n",
    "\n",
    "Входные параметры: угол поворота (angle)\n",
    "\n",
    "```python\n",
    "matrix = np.array([\n",
    "      [np.cos(angle),  np.sin(angle), 0],\n",
    "      [-np.sin(angle), np.cos(angle), 0],\n",
    "      [0,              0,             1],\n",
    "])\n",
    "```\n",
    "\n",
    "Формула поворота:\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} =\n",
    "\\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) & 0 \\\\\n",
    "                 \\sin(\\theta) & \\cos(\\theta) & 0 \\\\\n",
    "                 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Растяжение/сжатие (Scale)\n",
    "\n",
    "Входные параметры: фактор растяжения (sx, sy)\n",
    "\n",
    "```python\n",
    "matrix = np.array([\n",
    "      [s[0], 0,    0],\n",
    "      [0,    s[1], 0],\n",
    "      [0,    0,    1],\n",
    "])\n",
    "```\n",
    "\n",
    "Формула масштабирования:\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} =\n",
    "\\begin{bmatrix} s_x & 0 & 0 \\\\\n",
    "                 0 & s_y & 0 \\\\\n",
    "                 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Перенос (translation)\n",
    "\n",
    "Входные параметры: фактор переноса (tx, ty)\n",
    "\n",
    "```python\n",
    "matrix = np.array([\n",
    "      [1,  0, t[0]],\n",
    "      [0,  1, t[1]],\n",
    "      [0,  0,    1],\n",
    "])\n",
    "```\n",
    "\n",
    "Формула переноса:\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} =\n",
    "\\begin{bmatrix} 1 & 0 & t_x \\\\\n",
    "                 0 & 1 & t_y \\\\\n",
    "                 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Сдвиг (shearing)\n",
    "\n",
    "Входные параметры: фактор сдвига (kx, ky)\n",
    "\n",
    "```python\n",
    "matrix_horisontal = np.array([\n",
    "      [1,    k[0], 0],\n",
    "      [k[1], 1,    0],\n",
    "      [0,    0,    1],\n",
    "])\n",
    "```\n",
    "\n",
    "Формула сдвига:\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} =\n",
    "\\begin{bmatrix} 1 & k_x & 0 \\\\\n",
    "                 k_y & 1 & 0 \\\\\n",
    "                 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Типы трансформаций по степеням свободы\n",
    "\n",
    "![image_transformations](data/image_transformations.png)\n",
    "\n",
    "_Источник - [Computer Vision: Algorithms and Applications, 2nd ed. 2022 Richard Szeliski](https://szeliski.org/Book/)_\n",
    "\n",
    "#### Translation (Перенос)\n",
    "- Использует **2 параметра**: \\(t_x, t_y\\).\n",
    "- Сдвигает изображение без изменения формы.\n",
    "\n",
    "#### Euclidean (Rigid) (Евклидовы преобразования)\n",
    "- Использует **3 параметра**: угол поворота \\(\\theta\\) и сдвиги \\(t_x, t_y\\).\n",
    "- Сохраняет расстояния между точками, запрещая масштабирование и деформации.\n",
    "- Матрица вида:\n",
    "  $$\n",
    "  \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) & t_x \\\\\n",
    "                   \\sin(\\theta) & \\cos(\\theta) & t_y \\\\\n",
    "                   0 & 0 & 1 \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "#### Similarity (Подобие)\n",
    "- Использует **4 параметра**: поворот \\(\\theta\\), масштабирование \\(s\\), сдвиги \\(t_x, t_y\\).\n",
    "- Сохраняет пропорции, но допускает изменение масштаба.\n",
    "- Матрица:\n",
    "  $$\n",
    "  \\begin{bmatrix} s \\cos(\\theta) & -s \\sin(\\theta) & t_x \\\\\n",
    "                   s \\sin(\\theta) & s \\cos(\\theta) & t_y \\\\\n",
    "                   0 & 0 & 1 \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "#### Affine (Афинные преобразования)\n",
    "- Использует **6 параметров**: два столбца (2D-базис), сдвиг.\n",
    "- Сохраняет параллельность линий, но допускает масштабирование, поворот и сдвиг.\n",
    "- Матрица:\n",
    "  $$\n",
    "  \\begin{bmatrix} a_{11} & a_{12} & t_x \\\\\n",
    "                   a_{21} & a_{22} & t_y \\\\\n",
    "                   0 & 0 & 1 \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "#### Projective (Проективные преобразования)\n",
    "- Использует **8 параметров**, включая перспективные искажения.\n",
    "- Позволяет менять точки схода (например, для перспективного искажения).\n",
    "- Матрица:\n",
    "  $$\n",
    "  \\begin{bmatrix} a_{11} & a_{12} & t_x \\\\\n",
    "                   a_{21} & a_{22} & t_y \\\\\n",
    "                   p_1 & p_2 & 1 \\end{bmatrix}\n",
    "  $$\n",
    "- Используется в задачах **перспективного выравнивания**.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wYbJKHjJjpge"
   },
   "source": [
    "### Упражнение 4\n",
    "\n",
    "Реализуйте функцию, которая принимает изображение и матрицу преобразования, и реализует афинную трансформацию. Функция должна возвращать новое изображение после преобразования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SYKI5lpkGUc"
   },
   "outputs": [],
   "source": [
    "def make_rotation(params: list[float]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates a rotation matrix.\n",
    "\n",
    "    Args:\n",
    "        params (list[float]): [angle in radians]\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 3x3 rotation matrix\n",
    "    \"\"\"\n",
    "    angle = params[0]\n",
    "\n",
    "    mat = ...\n",
    "\n",
    "    return mat\n",
    "\n",
    "def make_scaling(params: list[float]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates a scaling matrix.\n",
    "\n",
    "    Args:\n",
    "        params (list[float]): [scaling factor for X, scaling factor for Y]\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 3x3 scaling matrix\n",
    "    \"\"\"\n",
    "    sx, sy = params[0], params[1]\n",
    "\n",
    "    mat = ...\n",
    "\n",
    "    return mat\n",
    "\n",
    "def make_translation(params: list[float]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates a translation matrix.\n",
    "\n",
    "    Args:\n",
    "        params (list[float]): [translation in X, translation in Y]\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 3x3 translation matrix\n",
    "    \"\"\"\n",
    "    tx, ty = params[0], params[1]\n",
    "\n",
    "    mat = ...\n",
    "\n",
    "    return mat\n",
    "\n",
    "def make_shearing(params: list[float]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates a shearing matrix.\n",
    "\n",
    "    Args:\n",
    "        params (list[float]): [shearing factor for X, shearing factor for Y]\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 3x3 shearing matrix\n",
    "    \"\"\"\n",
    "    shx, shy = params[0], params[1]\n",
    "\n",
    "    mat = ...\n",
    "\n",
    "    return mat\n",
    "\n",
    "def affine_transform(img: np.ndarray, mat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies an affine transformation to an image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image (numpy array)\n",
    "        mat (np.ndarray): 3x3 transformation matrix\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Transformed image\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sT6wT-FWmOqu"
   },
   "source": [
    "Проверьте код на примере изображения c астронавтом, запустите все 4 преобразования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444,
     "referenced_widgets": [
      "335df141f69f4e8a86597fd89766453e",
      "516edb46150543ac92b11d28fc7bb57c",
      "9d6628d50bcc4ac9bf6cecbaceeaaa0f",
      "50c82fa7aa8a4b6ca1618d0c188d5204",
      "576160f0c4894cfc98cb47faeecb55a0",
      "5d9010bf1312410eb82ac658249c0860",
      "1c0f1eb1d12d4381b50a4e30293e0f81",
      "ce5d532da25445ce8c67f9d690be1416",
      "636c6896494946fba4f6a66d6521500c",
      "94b278b92ff64a508bebfc585cee314a"
     ]
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1644863043351,
     "user": {
      "displayName": "Дмитрий Александрович Юдин",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09652559510612614952"
     },
     "user_tz": -180
    },
    "id": "F1SHG2z1k3AC",
    "outputId": "099c9e6b-ccc1-4525-a595-c5cd80432000"
   },
   "outputs": [],
   "source": [
    "astonaut_img = skimage.data.astronaut()\n",
    "\n",
    "rotation_matrix = make_rotation([np.radians(30)])\n",
    "scaling_matrix = make_scaling([1.5, 1.5])\n",
    "translation_matrix = make_translation([30, -80])\n",
    "shearing_matrix = make_shearing([0.3, 0.2])\n",
    "\n",
    "# Трансформированные изображения\n",
    "astonaut_rotated_img = affine_transform(astonaut_img, rotation_matrix)\n",
    "astonaut_scaled_img = affine_transform(astonaut_img, scaling_matrix)\n",
    "astonaut_translated_img = affine_transform(astonaut_img, translation_matrix)\n",
    "astonaut_sheared_img = affine_transform(astonaut_img, shearing_matrix)\n",
    "\n",
    "# Визуализация всех трансформаций\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "\n",
    "titles = [\"Original\", \"Rotation (30°)\", \"Scaling (1.5x)\", \"Translation (30, -80)\", \"Shearing (0.3, 0.2)\"]\n",
    "images = [astonaut_img, astonaut_rotated_img, astonaut_scaled_img, astonaut_translated_img, astonaut_sheared_img]\n",
    "\n",
    "for ax, img, title in zip(axes, images, titles):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение 5 - Картина \"Послы\" Ганса Гольбейна Младшего (1533)\n",
    "\n",
    "Картина \"Послы\" (1533) — произведение немецкого художника Ганса Гольбейна Младшего. На ней изображены два аристократа, а в нижней части композиции — искажённый череп. Этот эффект достигается с помощью анаморфозы — техники перспективного искажения, которое можно исправить, если рассчитать правильное аффинное преобразование.\n",
    "\n",
    "Подробнее: [Википедия](https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D1%81%D0%BB%D1%8B_(%D0%BA%D0%B0%D1%80%D1%82%D0%B8%D0%BD%D0%B0_%D0%93%D0%BE%D0%BB%D1%8C%D0%B1%D0%B5%D0%B9%D0%BD%D0%B0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оригинальная картина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![the_ambassadors](data/the_ambassadors.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Череп с исправленной геометрией\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если применить некоторые аффинные преобразования, можно привести искаженный череп в нижней части картины к нормальному виду:\n",
    "\n",
    "![the_ambassadors_skull_transformed](data/the_ambassadors_skull_transformed.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача\n",
    "\n",
    "1. Определите, какие аффинные преобразования нужно применить к искаженному черепу, чтобы получить нормальное изображение.\n",
    "2. Реализуйте эти преобразования и примените их к искаженному черепу.\n",
    "\n",
    "Для этого вам может понадобиться:\n",
    "\n",
    "- Найти координаты углов черепа на оригинальной картине.\n",
    "- Найти координаты углов черепа на искаженной картине.\n",
    "- Рассчитать матрицу преобразования между этими двумя наборами точек.\n",
    "- Применить это преобразование к искаженному черепу.\n",
    "\n",
    "Для выполнения задачи можно использовать следующие методы:\n",
    "\n",
    "1. **Ручное определение контрольных точек**\n",
    "   - Использовать `matplotlib.pyplot.ginput()` или OpenCV для интерактивного выбора точек на изображении.\n",
    "\n",
    "2. **Вычисление аффинной матрицы**\n",
    "   - Применить `cv2.getAffineTransform()`, если выбрано три контрольные точки.\n",
    "   - Если используется четыре точки, можно применить `cv2.getPerspectiveTransform()` для более точного исправления.\n",
    "\n",
    "3. **Применение трансформации**\n",
    "   - Использовать `cv2.warpAffine()` для аффинного преобразования.\n",
    "   - Использовать `cv2.warpPerspective()`, если применено перспективное преобразование.\n",
    "\n",
    "4. **Автоматическое определение контрольных точек** (более сложный вариант)\n",
    "   - Использование методов `ORB`, `SIFT` или `AKAZE` для детекции ключевых точек и сопоставления между искажённым и оригинальным изображением.\n",
    "   - Подбор гомографии с `cv2.findHomography()`.\n",
    "\n",
    "Вы можете реализовать решение этой задачи как внутри ноутбука, так и в виде отдельного Python-скрипта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dT3VvmwMwF79"
   },
   "source": [
    "## Формирование изображения\n",
    "\n",
    "### Внешние параметры камеры\n",
    "\n",
    "Некоторые камеры-обскуры вносят значительные искажения в изображения. Два основных вида искажений - это радиальные искажения и тангенциальные искажения.\n",
    "\n",
    "**Радиальные искажения** возникают из-за неидеальности линз и приводит к тому, что прямые линии кажутся изогнутыми.\n",
    "\n",
    "**Тангенциальные искажения** возникают из-за того, что объектив для съемки изображения не выровнен идеально параллельно плоскости изображения. Таким образом, некоторые области на изображении могут выглядеть ближе, чем ожидалось. \n",
    "\n",
    "Виды радиального искажения:\n",
    "<figure>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/63/Barrel_distortion.svg\" alt=\"drawing\" width=\"200\"/>\n",
    "<figcaption>Barrel distortion (Positive k1 > 0)</figcaption>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5b/Pincushion_distortion.svg\" alt=\"drawing\" width=\"200\"/>\n",
    "<figcaption>Pincushion distortion (Negative k1 < 0)</figcaption>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3c/Mustache_distortion.svg\" alt=\"drawing\" width=\"200\"/>\n",
    "<figcaption>Mustache distortion (Complex)</figcaption>\n",
    "</figure>\n",
    "\n",
    "**Формулы:**\n",
    "\n",
    "$x_{dist} = x\\frac{1+k_{1}r^{2}+k_{2}r^{4} + k_{3}r^{6}}{1+k_{4}r^{2}+k_{5}r^{4} + k_{6}r^{6}} + 2p_{1}xy + p_{2}(r^{2} + 2x^{2})$\n",
    "\n",
    "$y_{dist} = y\\frac{1+k_{1}r^{2}+k_{2}r^{4} + k_{3}r^{6}}{1+k_{4}r^{2}+k_{5}r^{4} + k_{6}r^{6}} + p_{1}(r^{2} + 2y^{2}) + 2p_{2}xy$,\n",
    "\n",
    "где $r^{2} = x^{2} + y^{2}$\n",
    "\n",
    "Таким образом, параметры радиальной дисторсии - ($k_{1}, \\cdots, k_{6}$), тангенциальной дисторсии - ($p_{1}, p_{2}$)\n",
    "\n",
    "В дополнение к этому нам нужны внутренние и внешние параметры камеры. Внутренние параметры специфичны для конкретной камеры. Они включают в себя такую информацию, как фокусное расстояние (fx,fy) и оптические центры (cx, cy). Фокусное расстояние и оптические центры могут быть использованы для создания матрицы камеры, которую можно использовать для устранения искажений, вызванных объективами конкретной камеры. Матрица камеры уникальна для конкретной камеры, поэтому после расчета ее можно повторно использовать на других изображениях, сделанных той же камерой."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OWAYgDem8Poa"
   },
   "source": [
    "### Вопрос 3\n",
    "\n",
    "Запишите выражение связи точек в координатной системе камеры (x, y, z) c проекцией (изображением), зная параметры дисторсии и параметры камеры.\n",
    "\n",
    "**Ответ:**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "i-4ajttX-2tL"
   },
   "source": [
    "### Упражнение 6\n",
    "\n",
    "Найдите параметры вашей камеры мобильного телефона. \n",
    "\n",
    "Используйте шаблон шахматной доски. Можете воспользоваться ресурсом https://markhedleyjones.com/projects/calibration-checkerboard-collection  - здесь можно выбрать необходимый размер и подготовить pdf с доской. Во время печати не забудьте проверить, что масштаб не меняется (часто в параметрах печати по умолчанию установлен флаг \"scale to fit page\").\n",
    "\n",
    "Воспользуйтесь [туториалом OpenCV](https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html).\n",
    "\n",
    "В ответе требуется:\n",
    "\n",
    "1. Загрузить все сделанные фотографии (туториал рекомендует использовать не менее 10-ти изображений) в папку `./data/calibr_images`. Написанный код должен воспроизводить ваши результаты без дополнительных манипуляций.\n",
    "2. Вывести найденные параметры калибровки (intrinsic матрицу и параметры дисторсии).\n",
    "3. Отобразить изображения до и после устранения дисторсии.\n",
    "4. Посчитать ошибку репроектирования (см. туториал opencv).\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1646232922667,
     "user": {
      "displayName": "Илья Валерьевич Башаров",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSB75QCZUCxiYM-Vchazusxi2F7XauhTXYbPy6=s64",
      "userId": "00847508316633118384"
     },
     "user_tz": -180
    },
    "id": "LD-XmTdy_-l4",
    "outputId": "7ec83358-1ca3-420f-9951-83a6f8629154"
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Seminar_4_wv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cv_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1c0f1eb1d12d4381b50a4e30293e0f81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "335df141f69f4e8a86597fd89766453e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [
       "widget-interact"
      ],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d6628d50bcc4ac9bf6cecbaceeaaa0f",
       "IPY_MODEL_50c82fa7aa8a4b6ca1618d0c188d5204",
       "IPY_MODEL_576160f0c4894cfc98cb47faeecb55a0"
      ],
      "layout": "IPY_MODEL_516edb46150543ac92b11d28fc7bb57c"
     }
    },
    "50c82fa7aa8a4b6ca1618d0c188d5204": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "ty",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_636c6896494946fba4f6a66d6521500c",
      "max": 3.14,
      "min": -3.14,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 0.01,
      "style": "IPY_MODEL_ce5d532da25445ce8c67f9d690be1416",
      "value": 1
     }
    },
    "516edb46150543ac92b11d28fc7bb57c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "576160f0c4894cfc98cb47faeecb55a0": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_94b278b92ff64a508bebfc585cee314a",
      "msg_id": "",
      "outputs": [
       {
        "ename": "TypeError",
        "evalue": "ignored",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipywidgets/widgets/interaction.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interact_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwarg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0mshow_inline_matplotlib_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_display\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-10-dce1061bca4e>\u001b[0m in \u001b[0;36mplay_with_params\u001b[0;34m(tx, ty)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# an example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     mat = make_rotation(\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-7-42a19ba904b1>\u001b[0m in \u001b[0;36mmake_rotation\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     mat = np.array(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     )\n",
         "\u001b[0;31mTypeError\u001b[0m: array() missing required argument 'object' (pos 1)"
        ]
       }
      ]
     }
    },
    "5d9010bf1312410eb82ac658249c0860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "636c6896494946fba4f6a66d6521500c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94b278b92ff64a508bebfc585cee314a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d6628d50bcc4ac9bf6cecbaceeaaa0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "tx",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_1c0f1eb1d12d4381b50a4e30293e0f81",
      "max": 3.14,
      "min": -3.14,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 0.01,
      "style": "IPY_MODEL_5d9010bf1312410eb82ac658249c0860",
      "value": 1
     }
    },
    "ce5d532da25445ce8c67f9d690be1416": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
